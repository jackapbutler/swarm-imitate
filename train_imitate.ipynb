{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from swarmi.net import Net, normalise, MultiNet\n",
    "from swarmi.operators import average_sampler_11D, normmeanprodop_sampler_11D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = int(1e4)\n",
    "max_pooling_agents = 20\n",
    "min_pooling_agents = 10\n",
    "\n",
    "n_hypotheses = 3\n",
    "op_name = 'Average'\n",
    "\n",
    "data = []\n",
    "for _ in range(num_points):\n",
    "    if op_name == 'Average':\n",
    "        x_values, w1s, w2s, w3s, w4s, w5s, target = average_sampler_11D(max_pooling_agents, min_pooling_agents, n_hypotheses, True, False)\n",
    "        data.append([[[*x] for x in zip(x_values, w1s, w2s, w3s, w4s, w5s)], target])\n",
    "    elif op_name == 'NormLogOp':\n",
    "        x_values, w1s, w2s, w3s, w4s, w5s, target = normmeanprodop_sampler_11D(max_pooling_agents, min_pooling_agents, n_hypotheses, True, False)\n",
    "        data.append([[[*x] for x in zip(x_values, w1s, w2s, w3s, w4s, w5s)], target])\n",
    "    else:\n",
    "        raise ValueError(f'Operator {op_name} not recognised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' # 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for sample in data:\n",
    "    formatted_agents = []\n",
    "    for agent in sample[0]:\n",
    "        belief_list = agent[0].tolist()    \n",
    "        flat_sample = [*belief_list, *agent[1:]]\n",
    "        formatted_agents.append(flat_sample)\n",
    "    \n",
    "    input_sample = torch.tensor(formatted_agents).squeeze(0).to(device)\n",
    "    input_sample = normalise(input_sample)\n",
    "    output = torch.tensor(sample[1]).to(device)\n",
    "    \n",
    "    xs.append(input_sample)\n",
    "    ys.append(output)\n",
    "\n",
    "n_train = int(0.80 * num_points)\n",
    "xs_train, xs_test = xs[:n_train], xs[n_train:]\n",
    "ys_train, ys_test = torch.vstack(ys[:n_train]), torch.vstack(ys[n_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = int(\n",
    "    torch.ceil(torch.exp(torch.tensor(min(max_pooling_agents ** (0.5), xs[0][0].shape[0])))).item()\n",
    ")\n",
    "neural_net = MultiNet(hidden_dim, n_hypotheses, agg_fn=torch.sum).to(device)\n",
    "optimiser = torch.optim.Adam(neural_net.parameters(), lr=3e-3)\n",
    "\n",
    "tr_losses = []\n",
    "te_losses = []\n",
    "NUM_EPOCHS = 50\n",
    "SAVE_MODEL = False\n",
    "LOG_INTERVAL = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMITATED_AVG_VARY_AGENTS_20MAXAGENTS_AVG_AGG_6D_MODEL_PATH = \"./models/imitated_avg_10k_50e_150width_20maxagents_6D_normalised_avg_agg.pt\"\n",
    "IMITATED_AVG_VARY_AGENTS_20MAXAGENTS_SUM_AGG_6D_MODEL_PATH = \"./models/imitated_avg_10k_50e_150width_20maxagents_6D_normalised_sum_agg.pt\"\n",
    "IMITATED_NORMPRODOP_VARY_AGENTS_20MAXAGENTS_AVG_AGG_6D_MODEL_PATH = \"./models/imitated_normprodop_10k_50e_150width_20maxagents_6D_normalised_avg_agg.pt\"\n",
    "IMITATED_MODEL_PATH = \"testing_multi_net.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(NUM_EPOCHS):\n",
    "    with torch.no_grad():\n",
    "        test_out = neural_net(xs_test)\n",
    "        test_loss = F.mse_loss(ys_test, test_out)\n",
    "        te_losses.append(test_loss.item())\n",
    "    \n",
    "    if e % LOG_INTERVAL == 0 or e == NUM_EPOCHS - 1 or e == 0:\n",
    "        print(f\"Epoch {e}: pred={test_out[0]} real={ys_test[0]} loss={round(te_losses[-1], 4)}\")\n",
    "\n",
    "    optimiser.zero_grad()\n",
    "    outs = neural_net(xs_train)\n",
    "    tr_loss = F.mse_loss(ys_train, outs)\n",
    "    tr_loss.backward()\n",
    "    optimiser.step()\n",
    "    tr_losses.append(tr_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if e == NUM_EPOCHS - 1 and SAVE_MODEL:\n",
    "    torch.save(neural_net, IMITATED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional saving of results\n",
    "SAVE_RESULT = True\n",
    "if SAVE_RESULT:\n",
    "    if not os.path.exists('scale_imitation_results.json'):\n",
    "        with open('scale_imitation_results.json', mode='w') as f:\n",
    "            json.dump({}, f)\n",
    "    with open('scale_imitation_results.json', mode='r') as f:\n",
    "        json_scores = json.load(f)\n",
    "        if op_name not in json_scores:\n",
    "            json_scores[op_name] = {}\n",
    "        json_scores[op_name][str(n_hypotheses)] = te_losses\n",
    "\n",
    "    with open('scale_imitation_results.json', mode='w') as f:\n",
    "        json.dump(json_scores, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scale_imitation_results.json', mode='r') as f:\n",
    "    json_scores = json.load(f)\n",
    "\n",
    "belief_ordered_results = {}\n",
    "for op, belief_scores in json_scores.items():\n",
    "    belief_scores = sorted(belief_scores.items(), key=lambda x: int(x[0]))\n",
    "    for belief, scores in belief_scores:\n",
    "        if belief not in belief_ordered_results:\n",
    "            belief_ordered_results[belief] = {}\n",
    "        belief_ordered_results[belief][op] = scores \n",
    "\n",
    "for belief, belief_scores in belief_ordered_results.items():\n",
    "    print(belief)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for op, scores in belief_scores.items():\n",
    "        plt.plot(scores, marker='o', markersize=6, label=op)\n",
    "    plt.xlabel('# Epochs', fontsize=16)\n",
    "    plt.ylabel('MSE Test Loss', fontsize=16)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
